## [Andrej Karpathy's "Let's build GPT: from scratch, in code, spelled out"](https://www.youtube.com/watch?v=kCc8FmEb1nY)

The video shows how to create a GPT-like language model step by step. He explains key concepts like tokenization, the transformer architecture (including self-attention and feedforward networks), and how positional embeddings work. Karpathy writes the code for each part, such as the transformer block and the training loop, and explains how to optimize and train the model. The video is a clear, hands-on guide for building a GPT model from scratch, focusing on both the theory and practical coding aspects.

## [## Andrej Karpathy's "Let's build the GPT Tokenizer"](https://www.youtube.com/watch?v=zduSFxRajkE)

This video provides a deeper dive into GPT's tokenization process. 

